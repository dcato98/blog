{
  
    
        "post0": {
            "title": "CUDA-Accellerated Julia Fractals",
            "content": "The Plan . In the first section, you&#39;ll learn how to generate impressively cool images like this one, commonly named the Mandelbrot set, both in NumPy and in PyTorch. . In the second section, you&#39;ll speed up your image generation by over a factor of 10, learning about broadcasting and the speedups that come from maxing out the GPU. . In the third section, you&#39;ll generate mesmerizing videos exploring the very fabric of Julia fractal-space. . . Above: The Mandelbrot set, which you&#39;ll be able to generate yourself by the end of Part 1. . Hang on...what is a Julia fractal? . Steven Wittens does an incredible job of showing what a Julia set is in his post How to Fold a Julia Fractal. If you need a refresher on Julia sets, or just want to marvel at Witten&#39;s impressive ability to build intuition through evocative visualizations, I suggest you take a few minutes to check it out now. Then return when you&#39;re ready to start coding. . Part 1: From Math to Code . A Julia fractal is computed by iteratively applying a function over a set of points in the complex plane. Mathematically, this looks like: . $$ z_{n+1} = f_n(z_n, c) $$ . Where $ f $ is a complex, non-linear function (i.e. map) and $ z_0 $ and $ c $ are both complex numbers. . By applying these maps iteratively over the points in the complex plane, the points that diverge to infinity are excluded from the Julia set. Those that don&#39;t diverge are part of the set. . Defining the complex plane . Let&#39;s get started defining the region of the complex plane we want to plot (xrange and yrange), as well as the resolution of our image. . xrange = yrange = (-2, 2) resolution = (5, 5) # (x-resolution, y-resolution) . Each point corresponds to one pixel, so in this case, we&#39;ll end up with a 5x5 pixel image with 25 points evenly spaced in the grid defined by the real x-axis ranging from -2 to 2, and the imaginary y-axis ranging from -2i to 2i. . This fully specifies our complex plane. Let&#39;s create this with NumPy: . import numpy as np def np_complex_plane(xrange=(-2,2), yrange=None, res=1024): &#39;&#39;&#39;Return a grid of points on the complex plane.&#39;&#39;&#39; # conveniences to simplify parameters if yrange == None: yrange = xrange # default: y-range = x-range if type(res) == int: res = (res,res) # default: x-resolution = y-resolution # define the x and y axis values on the (not yet) complex plane x = np.linspace(xrange[0], xrange[1], res[0]) # indexed backwards because images are indexed in the opposite direction on the y axis vs. the coordinate plane y = np.linspace(yrange[1], yrange[0], res[1]) # get a grid of points corresponding to the x (real) and y (complex) axis values real_plane, imag_plane = np.meshgrid(x, y) # convert points to complex numbers cplane = real_plane + 1j*imag_plane return cplane . Testing this complex plane generating function, we see that it matches our expectations. . np_complex_plane(xrange, yrange, resolution) . array([[-2.+2.j, -1.+2.j, 0.+2.j, 1.+2.j, 2.+2.j], [-2.+1.j, -1.+1.j, 0.+1.j, 1.+1.j, 2.+1.j], [-2.+0.j, -1.+0.j, 0.+0.j, 1.+0.j, 2.+0.j], [-2.-1.j, -1.-1.j, 0.-1.j, 1.-1.j, 2.-1.j], [-2.-2.j, -1.-2.j, 0.-2.j, 1.-2.j, 2.-2.j]]) . Converting this from NumPy to PyTorch is trivial. Because CUDA doesn&#39;t support complex numbers yet, we&#39;ll have to keep track of the real and imaginary values of the coordinates separately. . import torch def torch_complex_plane(xrange=(-2,2), yrange=None, res=1000): &#39;&#39;&#39;Return a 2-tuple of grids corresponding to the real and imaginary points on the complex plane, respectively.&#39;&#39;&#39; if yrange == None: yrange = xrange if type(res) == int: res = (res,res) # np.linspace(...) --&gt; torch.linspace(...).cuda() x = torch.linspace(xrange[0], xrange[1], res[0]).cuda() y = torch.linspace(yrange[1], yrange[0], res[1]).cuda() # np.meshgrid --&gt; torch.meshgrid real_plane, imag_plane = torch.meshgrid(x,y) cplane = tuple([real_plane.transpose(0,1), imag_plane.transpose(0,1)]) return cplane . Note the slight difference in the way we represent the complex plane in PyTorch compared to NumPy, above. The first element in the tuple is the real value of the point in the complex plane, the second is the imaginary value. . torch_complex_plane(xrange, yrange, resolution) . (tensor([[-2., -1., 0., 1., 2.], [-2., -1., 0., 1., 2.], [-2., -1., 0., 1., 2.], [-2., -1., 0., 1., 2.], [-2., -1., 0., 1., 2.]], device=&#39;cuda:0&#39;), tensor([[ 2., 2., 2., 2., 2.], [ 1., 1., 1., 1., 1.], [ 0., 0., 0., 0., 0.], [-1., -1., -1., -1., -1.], [-2., -2., -2., -2., -2.]], device=&#39;cuda:0&#39;)) . Defining divergence . Now that we have our complex plane, we need to know how to detect whether a point has diverged. This will determine what color we plot it. . Of course, we don&#39;t have an infinitely sized numeric data type to determine whether a point has &#39;reached infinity&#39; yet. On top of this, we don&#39;t have an infinite amount of time to find out whether each point exceeds this bound. . One way to approximate this is to count how many iterations it takes before a point exceeds a specified divergence_value, up to a fixed number of iterations, n_iterations. . divergence_value = 2 n_iterations = 50 . n_iterations is an especially convenient parameter because it directly manages our tradeoff between time and accuracy. More iterations take longer to compute, but result in higher quality maps. . Choosing a mapping function . Now that we know how to count convergence, we just need to choose a map. Let&#39;s recall our generating function: . $$ z_{n+1} = f_n(z_n, c) $$ . We&#39;ll spend most of our time here working with the most popular function for generating Julia fractals, the quadratic map: . $$ f(z) = z^2 + c $$ . Two other popular choices are the sine map (implemented at the very end) and cosine map (left as an exercise for the reader): . $$ f(z) = c * sin(z) $$ $$ f(z) = c * cos(z) $$ . Let&#39;s start by implementing the quadratic map in NumPy: . def np_quadratic_method(c, z, n_iterations, divergence_value): &#39;&#39;&#39;Iteratively apply the quadratic map `z = z^2 + c` for `n_iterations` times c: constant complex value z: initial complex values &#39;&#39;&#39; # initialize matrix of counters stable_steps = np.zeros_like(z, dtype=np.int32) for i in range(n_iterations): # mask keeps track of the points that have not diverged yet mask = np.less(np.abs(z), divergence_value) # increment counter for all points that haven&#39;t diverged yet stable_steps += mask # do one iteration of the function # (for performance, only update the points that haven&#39;t diverged yet) try: # update z when c is a matrix of complex numbers z[mask] = z[mask]**2 + c[mask] except: # update z when c is a single complex number z[mask] = z[mask]**2 + c # normalize values to the range [0,1] return stable_steps / n_iterations . Finally, to visually verify our model, let&#39;s choose a value for c for which the image is already known. Paul Bourke lists of some particularly interesting on his website. I like $ c = 0.54 + 0.54i $, which, according to Bourke&#39;s website, looks like this: . . c = -0.54 + 0.54j z_init = np_complex_plane(xrange, yrange, resolution) img = np_quadratic_method(c, z_init, n_iterations, divergence_value) img . array([[0. , 0. , 0. , 0. , 0. ], [0. , 0.04, 0.06, 0.02, 0. ], [0. , 0.08, 1. , 0.08, 0. ], [0. , 0.02, 0.06, 0.04, 0. ], [0. , 0. , 0. , 0. , 0. ]]) . Plotting a Julia set . This is difficult to inspect by eye. Let&#39;s write a function to plot these values. By experimentation, I&#39;ve found that plotting the negative log of the returned values usually gives a nice contrast of values. eps controls the sensitivity to values very close to zero. . import matplotlib.pyplot as plt def np_plot_julia(julia_img, sz=16, eps=.1): img = -np.log(julia_img + eps) plt.figure(figsize=(sz,sz)) plt.imshow(img) plt.show() . np_plot_julia(img, sz=6) . Hmm...looks like we don&#39;t have enough resolution to get a clear picture. . resolution = 64 c = -0.54 + 0.54j z_init = np_complex_plane(xrange, yrange, resolution) img = np_quadratic_method(c, z_init, n_iterations, divergence_value) np_plot_julia(img, sz=6) . This is looking promising! Let&#39;s increase the resolution even further, and make the image bigger for a better comparison. . resolution = 1024 c = -0.54 + 0.54j z_init = np_complex_plane(xrange, yrange, resolution) img = np_quadratic_method(c, z_init, n_iterations, divergence_value) np_plot_julia(img, sz=12) . We&#39;re starting to get very close to the original, but we&#39;re lacking in detail. Let&#39;s increase how many iterations we do from 50 to 200 iterations. . n_iterations = 200 c = -0.54 + 0.54j z_init = np_complex_plane(xrange, yrange, resolution) img = np_quadratic_method(c, z_init, n_iterations, divergence_value) np_plot_julia(img, sz=12) . Looks like the same fractal to me! . And along the way, we&#39;ve seen how to improve the quality of our generated images by increasing the image resolution and/or increasing the number of iterations. . Accelerating the quadratic map . Okay, now that it looks like we&#39;ve got the NumPy implementation correct, let&#39;s reimplement the quadratic map in PyTorch. . def torch_complex_magnitude(r,i): &#39;&#39;&#39;returns the magnitude of a complex tensor, given a real component, `r`, and an imaginary component, `i`&#39;&#39;&#39; return torch.sqrt(r**2+i**2) def torch_quadratic_method(c, z, n_iterations, divergence_value): &#39;&#39;&#39;Iteratively apply the quadratic map `z = z^2 + c` for `n_iterations` times c: tuple of the real and imaginary components of the constant value z: tuple of the real and imaginary components of the initial z-value &#39;&#39;&#39; # np.zeros_like(...) --&gt; torch.zeros_like(...).cuda() stable_steps = torch.zeros_like(z[0]).cuda() for i in range(n_iterations): # numpy handled squaring complex magnitudes, for PyTorch we implement this ourselves mask = torch.lt(torch_complex_magnitude(*z), divergence_value) stable_steps += mask.to(torch.float32) # likewise, we manually implement one iteration of the quadratic map z = (z[0]**2-z[1]**2 + c[0], # real 2*z[0]*z[1] + c[1]) # imaginary # don&#39;t forget to put the array onto the cpu for plotting! return (stable_steps / n_iterations).cpu() . It&#39;s trivial to convert our plotting function from NumPy to PyTorch: . def torch_plot_julia(julia_img, sz=16, eps=.1): # np.log --&gt; torch.log img = -torch.log(julia_img + eps) plt.figure(figsize=(sz,sz)) plt.imshow(img) plt.show() . Now let&#39;s replicate the spiral fractal using our PyTorch code . resolution = 1024 # As before, note the change from using the built-in complex data type, which NumPy can handle # to using the convention: [real, imaginary], which we manually handle using PyTorch c = [-0.54, 0.54] z_init = torch_complex_plane(xrange, yrange, resolution) img = torch_quadratic_method(c, z_init, n_iterations, divergence_value) torch_plot_julia(img, sz=12) . Nice! Looks identical to our NumPy version. . So we used a constant value for c to create this image, but the famous Mandelbrot set is generated by varying c, setting it equal the complex plane. That is, c varies for each point in the plane, so that c is equal to the coordinate at that point. . We can actually already do this, using the same function we use to initialize the complex plane! Let&#39;s test it out: . # Mandelbrot set c = torch_complex_plane(xrange, yrange, resolution) z_init = torch_complex_plane(xrange, yrange, resolution) img = torch_quadratic_method(c, z_init, n_iterations, divergence_value) torch_plot_julia(img, sz=6) . Although it is perhaps not as striking as the image of the Mandelbrot set on Wikipedia (see below), it looks like we&#39;ve successfully replicated it! . . Part 2: Broadcasting - From One to Many . This tiny change illustrates the power of broadcasting. Broadcasting is what makes this so amazingly efficient. If you&#39;ve never heard of broadcasting, here&#39;s a good place to review it. Skip to the section on &#39;Broadcasting Rules&#39; if just need a quick refresher. Take all the time you need, I&#39;m not going anywhere. . Good? Good. . Updating the data model . So, what area is a good candidate for speeding up? We can&#39;t easily parallelize the calculation of an image any further due to the iterative nature of the calculation. However, we can compute multiple images in parallel. . Right now, we&#39;re generating 1 image, in 2 dimensions (x, y). This is defined by our variable, resolution, and is reflected in the shape of our constant, c, and $ z_0 $ , z_init. . resolution, c[0].shape, z_init[0].shape . (1024, torch.Size([1024, 1024]), torch.Size([1024, 1024])) . One way to do this is to vary our complex constant, c, generating multiple images. For example, we can add a new dimension in front, describing how many images to calculate at once, sampling c along the complex plane. I&#39;ll refer to this as the grid of images. . I&#39;ll demonstrate this directly in PyTorch to get the immediate speed advantages, although it is straightforward to transcribe into NumPy. . # number of images in x and y directions grid_resolution = 5 # sample c evenly between these values grid_xrange = grid_yrange = [-2, 2] # number of pixels in each image image_resolution = 64 # range of complex valued points in each image image_xrange = image_yrange = [-2, 2] # take note the dimensions here c_real, c_imag = [ri.reshape(grid_resolution, grid_resolution, 1, 1) for ri in torch_complex_plane(grid_xrange, grid_yrange, grid_resolution)] # take note of the dimensions here z_real, z_imag = [ri.reshape(1, 1, image_resolution, image_resolution) for ri in torch_complex_plane(image_xrange, image_yrange, image_resolution)] c_real.shape, z_real.shape . (torch.Size([5, 5, 1, 1]), torch.Size([1, 1, 64, 64])) . Now look at the resulting shape when we add c to z: . (c_real + z_real).shape . torch.Size([5, 5, 64, 64]) . The way to interpret this is that we&#39;re broadcasting the initialization of the complex plane, z, across every individual value of c, effectively representing a 5x5 grid of images, each with dimension 64x64. The image at [0,0,:,:] will represent the top-left-most value of c, which according to grid_xrange and grid_yrange is $ c = -2 + 2i $. . If you don&#39;t follow this yet, don&#39;t worry! Note your confusion, continue reading, and circle back after seeing what we&#39;re going to do with this. This is not easy to follow, but I ask that you please trust me, we&#39;re nearly there and it will all make sense very soon. . Let&#39;s generalize the creation of c and z. . def make_cz_grids(grid_res, img_res, grid_x_rng=(-2,2), grid_y_rng=(-2,2), img_x_rng=(-2,2), img_y_rng=(-2,2)): if type(grid_res) == int: grid_res = (grid_res, grid_res) if type(img_res ) == int: img_res = (img_res , img_res ) c = [x.reshape(grid_res[0],grid_res[1],1,1) for x in torch_complex_plane(grid_x_rng, grid_y_rng, grid_res)] z = [x.reshape(1,1,img_res[0],img_res[1]) for x in torch_complex_plane(img_x_rng, img_x_rng, img_res)] return c,z . c, z = make_cz_grids(grid_resolution, image_resolution) (c[0] + z[0]).shape . torch.Size([5, 5, 64, 64]) . Now that we&#39;ve updated our variables, let&#39;s update our method. Note that, because of broadcasting, we only need to change one line of code. . Updating the iteration method . I suggest you take a moment to read through this function to convince yourself that this will work. . def torch_quadratic_method(c, z, n_iterations, divergence_value): &#39;&#39;&#39;Iteratively apply the quadratic map `z = z^2 + c` for `n_iterations` times c: tuple of the real and imaginary components of the constant value z: tuple of the real and imaginary components of the initial z-value &#39;&#39;&#39; # add c[0] to get the right shape stable_steps = torch.zeros_like(c[0] + z[0]).cuda() for i in range(n_iterations): mask = torch.lt(torch_complex_magnitude(*z), divergence_value) stable_steps += mask.to(torch.float32) z = (z[0]**2-z[1]**2 + c[0], # real 2*z[0]*z[1] + c[1]) # imaginary return (stable_steps / n_iterations).cpu() . This is but a small taste of the power and the beauty of broadcasting. Once we set up an appropriate data model, we get parallelization for free. . Time to test this out. . n_iterations = 50 c, z = make_cz_grids(grid_resolution, image_resolution) imgs = torch_quadratic_method(c, z, n_iterations, divergence_value) imgs.shape . torch.Size([5, 5, 64, 64]) . This is the output shape we expected. Now let&#39;s plot these images! . Plotting a grid of Julia sets . def torch_plot_julia_grid(images, figsize=(12,12)): rows, cols = images.shape[:2] fig, axs = plt.subplots(rows, cols, figsize=figsize) for i in range(rows): for j in range(cols): axs[i,j].imshow(images[i,j]) axs[i,j].get_xaxis().set_visible(False) axs[i,j].get_yaxis().set_visible(False) plt.show() . torch_plot_julia_grid(imgs) . This is a start, but it&#39;s not quite clear yet whether we&#39;ve actually done it right. Let&#39;s try increasing the resolution of our grid and zoom in on the appropriate region. . # this is the main region where the Mandelbrot set exists # and also happens to be where the Julia sets are connected grid_x_rng = (-1.5, 0.5) grid_y_rng = (-1, 1) grid_resolution = 21 image_resolution = 512 c, z = make_cz_grids(grid_resolution, image_resolution, grid_x_rng=grid_x_rng, grid_y_rng=grid_y_rng) imgs = torch_quadratic_method(c, z, n_iterations, divergence_value) torch_plot_julia_grid(imgs, figsize=(16,16)) . This looks pretty good! . And what does one of these images look like? . x = 15 y = 2 print(f&#39;c = {c[0][y][x][0][0]:0.3f} + {c[1][y][x][0][0]:0.3f}i&#39;) torch_plot_julia(imgs[y, x], sz=8) . c = 0.000 + 0.800i . This particular Julia set ($ c = 0 + 0.8i $) is also on Bourke&#39;s website. Let&#39;s compare: . . Looks like I probably mixed up my axes somewhere, causing a problem with symmetry. Maybe I&#39;ll get to fixing this someday. If you happen to spot it, let me know where I went wrong! (tweet me: @dcato98) . Now that you&#39;ve seen what we can do with broadcasting, this a good time to go back to the beginning of the section and review the changes necessary to make this work. . Finally, I promised you we&#39;d make a video to visualize the Julia fractal in another way. Let&#39;s get to work. . Part 3: Visualizing the Julia set as a video . To create the video we&#39;ll be using ffmpeg. If you want to follow along with this section, make sure you have it installed. I&#39;d suggest a link, but installation varies across platforms so I&#39;ll leave you to search for instructions relevant to your situation. . Preparing the video frames . For this video, let&#39;s visualize varying c along the real x-axis, holding the imaginary y-axis constant at 0.25i. . First, we&#39;ll use the code we&#39;ve already written to generate our frames. If your GPU runs out of memory at this point, try decreasing either the image resolution or the number of frames. . One way to get around this and create large videos at high quality would be to create and save the images in smaller batches before creating video (don&#39;t forget to name the frames in sequence!). . # vary the c-values along the x-axis grid_x_rng = (-1.5, 0.5) # hold the y-axis constant grid_y_rng = (0.25, 0.25) # define number of frames grid_resolution = (120, 1) # image quality parameters image_resolution = 1024 n_iterations = 200 c, z = make_cz_grids(grid_resolution, image_resolution, grid_x_rng, grid_y_rng) imgs = torch_quadratic_method(c, z, n_iterations, divergence_value) # temporarily reshape our images into a square grid to easily visualize our frames torch_plot_julia_grid(imgs.reshape(10,12,image_resolution, image_resolution), figsize=(16,16)) . Looks good. Now let&#39;s smoosh together the grid, treating imgs as a list, not a grid, of images. . imgs = imgs.reshape(-1, image_resolution, image_resolution) imgs.shape . torch.Size([120, 1024, 1024]) . Next let&#39;s set up our file paths. . We need a working directory, path, a subfolder in this location for saving a the list of images, frame_folder, and a filename which we&#39;ll name the video, video_fn. . from pathlib import Path # set this to your preferred working directory path = Path(&#39;/home/dc&#39;) frame_folder = path / f&#39;julia_frames&#39; # save the video here # video_fn = path / &#39;julia_visualization.mp4&#39; # for some reason, I couldn&#39;t play .mp4 files in the notebook video_fn = path / &#39;julia_visualization.webm&#39; # MUCH slower to convert, also it looks like it might be resolution, try mp4 first # create the frame folder frame_folder.mkdir(exist_ok=True, parents=True) . # save images into the frame folder, this can take a while for i, img in enumerate(imgs): fig = plt.figure(figsize=(16,16)) plt.imshow(img) # turn off axis ticks plt.xticks([]) plt.yticks([]) # save image to `frame_folder` directory plt.savefig(frame_folder / f&#39;julia_{i:08d}.png&#39;) # prevent plot from displaying in notebook, also reduces memory use plt.close(fig) . Creating a video . # set the frame rate fps = 30 # fps=frames per second # change working directory to the frame folder old_wd = Path.cwd() frame_folder.cwd() image_path_format = frame_folder / &#39;julia_%08d.png&#39; # create video #! ffmpeg -r $fps -i $image_path_format -pix_fmt yuv420p -y $video_fn ! ffmpeg -r $fps -i $image_path_format -y $video_fn # return to old working directory old_wd.cwd() . ffmpeg version 4.0 Copyright (c) 2000-2018 the FFmpeg developers built with gcc 7.2.0 (crosstool-NG fa8859cb) configuration: --prefix=/home/dc/anaconda3/envs/fastai --cc=/opt/conda/conda-bld/ffmpeg_1531088893642/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-shared --enable-static --enable-zlib --enable-pic --enable-gpl --enable-version3 --disable-nonfree --enable-hardcoded-tables --enable-avresample --enable-libfreetype --disable-openssl --disable-gnutls --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --disable-libx264 libavutil 56. 14.100 / 56. 14.100 libavcodec 58. 18.100 / 58. 18.100 libavformat 58. 12.100 / 58. 12.100 libavdevice 58. 3.100 / 58. 3.100 libavfilter 7. 16.100 / 7. 16.100 libavresample 4. 0. 0 / 4. 0. 0 libswscale 5. 1.100 / 5. 1.100 libswresample 3. 1.100 / 3. 1.100 libpostproc 55. 1.100 / 55. 1.100 Input #0, image2, from &#39;/home/dc/julia_frames/julia_%08d.png&#39;: Duration: 00:00:04.80, start: 0.000000, bitrate: N/A Stream #0:0: Video: png, rgba(pc), 1152x1152 [SAR 2834:2834 DAR 1:1], 25 fps, 25 tbr, 25 tbn, 25 tbc Stream mapping: Stream #0:0 -&gt; #0:0 (png (native) -&gt; vp9 (libvpx-vp9)) Press [q] to stop, [?] for help [libvpx-vp9 @ 0x55bab7fa2fc0] v1.7.0 Output #0, webm, to &#39;/home/dc/julia_visualization.webm&#39;: Metadata: encoder : Lavf58.12.100 Stream #0:0: Video: vp9 (libvpx-vp9), yuva420p, 1152x1152 [SAR 1:1 DAR 1:1], q=-1--1, 200 kb/s, 30 fps, 1k tbn, 30 tbc Metadata: encoder : Lavc58.18.100 libvpx-vp9 Side data: cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1 frame= 120 fps=1.2 q=0.0 Lsize= 111kB time=00:00:03.96 bitrate= 228.6kbits/s speed=0.0402x video:100kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 10.341538% . PosixPath(&#39;/home/dc/git/blog/_notebooks&#39;) . Playing our video . This needs no explanation. Sit back and enjoy :) . from ipywidgets import Video Video.from_file(video_fn) . . And there you have it! This is a visualization of the Julia set when $ c = r + 0.25i $ where $ r epsilon[-1.5, 0.5] $. . What&#39;s next? . There are so many fun directions to go from here! Here&#39;s a few ideas: . Colorization: Try experimenting with different thresholds, multiple colors, etc... A quick google search turns up many amazing examples. Can you replicate these? Can you invent your own? | Map: There&#39;s nothing inherently special about the quadratic map. It&#39;s well studied, but try exploring fractals made from another map. | Video: Instead of updating c in a line, consider updating c to travel in a circle or other continuous curve. Or, continuously zoom in on a particularly interesting patch. | 3D: Our image grid and video are 2 ways to try to grasp the shape of a 4D object. What would this object look like in 3D (say, by holding the real or imaginary component of c constant). Then, create a video of the 3D object as you travel along the 4th dimension. | Batching: Occasionally when I wrote this, I experimented with large parameters which caused the GPU to run out of memory (e.g. when creating the video) and requiring the notebook to be restarted - batching what gets sent to the GPU could prevent this from happening. | . For a bit of inspiration, here&#39;s an example of experimenting with colorization and maps to generate &quot;electric christmas trees&quot; Set is(see image below) generated using the Sine map! . First, I&#39;ve refactored our code a bit to make our Julia generator and plotting functions more generic: . # implement the quadratic and Sine maps for complex numbers def torch_quadratic_map(c, z): return (z[0]**2-z[1]**2 + c[0], 2*z[0]*z[1] + c[1]) # modify our quadratic julia method to generalize to any mapping function def torch_julia_generator(c=None, z=None, n_iterations=50, divergence_value=50, map_func=torch_quadratic_map): &#39;&#39;&#39;A generic julia fractal generator (defaults produce the Mandelbrot set).&#39;&#39;&#39; if c is None: c = torch_complex_plane() if z is None: z = torch_complex_plane() stable_steps = torch.zeros_like(c[0]+z[0]).cuda() for i in range(n_iterations): mask = torch.lt(z[1].abs(), divergence_value) stable_steps += mask.to(torch.float32) z = map_func(c, z) return (stable_steps / n_iterations).cpu() # add `transform_func` to our standard plotting function to accept arbitrary image transformations def torch_plot_julia(julia_img, sz=16, eps=.1, transform_func=None): img = -torch.log(julia_img + eps) if transform_func is None else transform_func(julia_img) plt.figure(figsize=(sz,sz)) plt.imshow(img) plt.show() . Testing the default Julia generator: . torch_plot_julia(torch_julia_generator()) . Now, we implement the Sine map. Look how easy this is with our newly refactored code! . # implementing the Sine map in PyTorch def torch_complex_mult(ar,ai,br,bi): return (ar*br-ai*bi, ar*bi+ai*br) def torch_complex_sin(r,i): return (torch.sin(r)*torch.cosh(i), torch.sinh(i)*torch.cos(r)) def torch_sin_map(c, z): return torch_complex_mult(*torch_complex_sin(*z), *c) . After exploring the Sine map, this is one of my favorites! . # parameters for the Electric Christmas Trees fractal map_func = torch_sin_map c = [1.0, 0.1] xrange = yrange = (-5,5) print(&#39;Electric Christmas Trees! (Sine map: c = 1.0 + 0.1i)&#39;) # image quality parameters resolution = 1024 n_iterations = 256 figsize = 16 tranform_func = lambda x: x # don&#39;t transform the output, default is do: -log(julia_img) # putting it all together! z = torch_complex_plane(xrange, yrange, resolution) img = torch_julia_generator(c, z, n_iterations, divergence_value, map_func=map_func) torch_plot_julia(img, sz=figsize, transform_func=tranform_func) . Electric Christmas Trees! (Sine map: c = 1.0 + 0.1i) . I&#39;m excited to see where you take this. Tweet me at @dcato98 with a pic/video of your amazing creations! .",
            "url": "https://dcato98.github.io/blog/jupyter/visualization/python/cuda/numpy/pytorch/video/2020/04/28/CUDA-Accelerated-Julia-Fractals.html",
            "relUrl": "/jupyter/visualization/python/cuda/numpy/pytorch/video/2020/04/28/CUDA-Accelerated-Julia-Fractals.html",
            "date": " • Apr 28, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Zip and Unzip in Python",
            "content": "Overview: . select files in directory | select a sample of files | write sampled filepaths into csv | zip sampled files | unzip sampled files | read sampled filepaths from csv | from pathlib import Path from fastai.vision import get_image_files import numpy as np from zipfile import ZipFile . # working directory path = Path(&#39;/home/dc/coronahack/source/nih-chest-xrays&#39;) # source directory containing files to zip src_dir = path / &#39;data&#39; # csv filepath (to be created/overwritten) csv_dst = path / &#39;nih-chest-xrays_sample-2000.csv&#39; # zip filepath (to be created/overwritten) zip_dst = path / &#39;nih-chest-xrays_sample-2000.zip&#39; # unzip directory (to be created/overwritten) unzip_dst = path / &#39;sample-2000&#39; . Create Zip . 1. Select files in specified directory . (e.g all image files in dir + subdirs) . files = sorted(get_image_files(src_dir, recurse=True)) len(files), files[:5] . (112120, [PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_001/images/00000001_000.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_001/images/00000001_001.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_001/images/00000001_002.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_001/images/00000002_000.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_001/images/00000003_000.png&#39;)]) . 2. Randomly sample n files from list . (optional: set seed) . n = 2000 seed = np.random.randint(0, 2**32-1) # seed = 0 np.random.seed(seed) sample_paths = np.random.choice(files, n, replace=False) sample_paths . array([PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_007/images/00014129_003.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_008/images/00017368_000.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_003/images/00005798_002.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_010/images/00021488_002.png&#39;), ..., PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_004/images/00007094_000.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_009/images/00019415_001.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_002/images/00002271_000.png&#39;), PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_002/images/00003658_005.png&#39;)], dtype=object) . 3. Write csv of original file paths into csv_dst file . csv_dst.exists(), csv_dst . (True, PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/nih-chest-xrays_sample-2000.csv&#39;)) . np.savetxt(csv_dst, sample_paths.astype(np.str), fmt=&#39;%s&#39;, delimiter=&#39;,&#39;) . 4. Zip files in list into zip_dst file . zip_dst.exists(), zip_dst . (True, PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/nih-chest-xrays_sample-2000.zip&#39;)) . with ZipFile(zip_dst,&#39;w&#39;) as zf: for fn in sample_paths: zf.write(fn) . Unzip files . 5. Unzip files into unzip_dst folder . unzip_dst.mkdir(parents=True, exist_ok=True) unzip_dst.exists(), unzip_dst . (True, PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/sample-2000&#39;)) . with ZipFile(zip_dst, &#39;r&#39;) as zf: # zf.printdir() # print zip contents zf.extractall(unzip_dst) . 6. Load csv of original file paths . csv_dst.exists(), csv_dst . (True, PosixPath(&#39;/home/dc/coronahack/source/nih-chest-xrays/nih-chest-xrays_sample-2000.csv&#39;)) . np.loadtxt(csv_dst, dtype=np.str, delimiter=&#39;,&#39;) . array([&#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_007/images/00014129_003.png&#39;, &#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_008/images/00017368_000.png&#39;, &#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_003/images/00005798_002.png&#39;, &#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_010/images/00021488_002.png&#39;, ..., &#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_004/images/00007094_000.png&#39;, &#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_009/images/00019415_001.png&#39;, &#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_002/images/00002271_000.png&#39;, &#39;/home/dc/coronahack/source/nih-chest-xrays/data/images_002/images/00003658_005.png&#39;], dtype=&#39;&lt;U82&#39;) .",
            "url": "https://dcato98.github.io/blog/jupyter/python/quick-demo/2020/04/18/Zip-and-Unzip-in-Python.html",
            "relUrl": "/jupyter/python/quick-demo/2020/04/18/Zip-and-Unzip-in-Python.html",
            "date": " • Apr 18, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://dcato98.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://dcato98.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi there, I’m David, and welcome to my experimental blogspace. . I’m currently looking for opportunities to build AI-powered tools as a machine learning engineer (or similar), especially those that aim to improve human communication, connection, learning, and insight. I intend to expand on my goals in a future post. . I plan on using this as a place to highlight a few of my my projects, tutorials, lists, and other thoughts. I would love to hear what you think. Get in touch with me on LinkedIn: david-cato or Twitter: @dcato98. . . This website is powered by fastpages, a blogging platform that natively supports Jupyter notebooks and other formats. Thank you especially to @hamelsmu for your work building this tool and also to @1littlecoder for your video which made an already simple setup process even easier! .",
          "url": "https://dcato98.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}